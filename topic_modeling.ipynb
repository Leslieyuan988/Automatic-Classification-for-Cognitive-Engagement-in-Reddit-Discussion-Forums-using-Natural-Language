{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004ce5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction import text\n",
    "import numpy as np\n",
    "from gensim import matutils, models\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2305c",
   "metadata": {},
   "source": [
    "#### Retrieve the preprocessed text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854b26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = \"data_preprocessed\"\n",
    "\n",
    "open_file = open(file_name, \"rb\")\n",
    "data_lemmatized_NA = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2f355",
   "metadata": {},
   "source": [
    "# Document Term Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27655305",
   "metadata": {},
   "source": [
    "#### Bad of Words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab19a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "id2word = corpora.Dictionary(data_lemmatized_NA)\n",
    "texts = data_lemmatized_NA\n",
    "corpus_new = [id2word.doc2bow(text) for text in texts] # BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e7db1",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669c6c2",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA) Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199a5f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"day\" + 0.010*\"place\" + 0.009*\"friend\" + 0.009*\"right\" + 0.009*\"work\" + 0.008*\"man\" + 0.008*\"reason\" + 0.008*\"guy\" + 0.008*\"big\" + 0.007*\"world\"'),\n",
       " (1,\n",
       "  '0.037*\"people\" + 0.032*\"time\" + 0.024*\"thing\" + 0.023*\"good\" + 0.019*\"way\" + 0.014*\"year\" + 0.013*\"post\" + 0.011*\"many\" + 0.009*\"life\" + 0.009*\"question\"'),\n",
       " (2,\n",
       "  '0.023*\"game\" + 0.014*\"lot\" + 0.013*\"well\" + 0.011*\"bad\" + 0.010*\"character\" + 0.010*\"part\" + 0.010*\"player\" + 0.009*\"comment\" + 0.009*\"point\" + 0.008*\"money\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_3 = models.LdaModel(corpus=corpus_new, num_topics=3, id2word=id2word, passes=10)\n",
    "lda_3.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744bb20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.029*\"thing\" + 0.018*\"year\" + 0.016*\"lot\" + 0.016*\"post\" + 0.013*\"bad\" + 0.012*\"life\" + 0.011*\"work\" + 0.010*\"right\" + 0.010*\"comment\" + 0.010*\"man\"'),\n",
       " (1,\n",
       "  '0.031*\"way\" + 0.024*\"day\" + 0.019*\"well\" + 0.015*\"much\" + 0.014*\"player\" + 0.013*\"point\" + 0.013*\"different\" + 0.011*\"reddit\" + 0.010*\"last\" + 0.009*\"job\"'),\n",
       " (2,\n",
       "  '0.050*\"people\" + 0.015*\"many\" + 0.012*\"part\" + 0.010*\"place\" + 0.010*\"big\" + 0.010*\"person\" + 0.009*\"woman\" + 0.009*\"level\" + 0.009*\"sure\" + 0.009*\"use\"'),\n",
       " (3,\n",
       "  '0.044*\"time\" + 0.032*\"good\" + 0.029*\"game\" + 0.013*\"question\" + 0.012*\"character\" + 0.012*\"friend\" + 0.011*\"able\" + 0.011*\"reason\" + 0.011*\"money\" + 0.010*\"new\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_4 = models.LdaModel(corpus=corpus_new, num_topics=4, id2word=id2word, passes=10)\n",
    "lda_4.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4daf2137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.072*\"people\" + 0.022*\"many\" + 0.018*\"life\" + 0.018*\"question\" + 0.018*\"much\" + 0.016*\"right\" + 0.013*\"sure\" + 0.013*\"action\" + 0.012*\"problem\" + 0.010*\"least\"'),\n",
       " (1,\n",
       "  '0.028*\"way\" + 0.019*\"lot\" + 0.017*\"well\" + 0.017*\"new\" + 0.014*\"place\" + 0.014*\"work\" + 0.011*\"big\" + 0.011*\"system\" + 0.009*\"gt\" + 0.008*\"high\"'),\n",
       " (2,\n",
       "  '0.056*\"time\" + 0.022*\"post\" + 0.015*\"character\" + 0.015*\"part\" + 0.014*\"able\" + 0.014*\"different\" + 0.012*\"first\" + 0.012*\"woman\" + 0.012*\"reddit\" + 0.012*\"level\"'),\n",
       " (3,\n",
       "  '0.046*\"thing\" + 0.020*\"bad\" + 0.015*\"man\" + 0.015*\"reason\" + 0.015*\"money\" + 0.013*\"issue\" + 0.012*\"great\" + 0.011*\"child\" + 0.011*\"story\" + 0.011*\"old\"'),\n",
       " (4,\n",
       "  '0.041*\"good\" + 0.037*\"game\" + 0.025*\"day\" + 0.025*\"year\" + 0.015*\"player\" + 0.015*\"friend\" + 0.014*\"comment\" + 0.013*\"guy\" + 0.013*\"person\" + 0.012*\"world\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_5 = models.LdaModel(corpus=corpus_new, num_topics=5, id2word=id2word, passes=10)\n",
    "lda_5.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf75404",
   "metadata": {},
   "source": [
    "By human interpretation, the result show us the possible topics that LDA can achieved and it looks decent, but we are unsure about the optimal number of topics, number of iteration and more just by human judgement. Therefore it is important to get a grasp on the parameters involved in LDA and perform fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036feb07",
   "metadata": {},
   "source": [
    "#### Coherence Score of Base Model\n",
    "Ideally, we can train different LDA models by computing the coherence score of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacde515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.49215920826769033\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score for the base model\n",
    "coherence_model_lda = CoherenceModel(model=lda_3, texts=data_lemmatized_NA, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score for 3 topics: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_4, texts=data_lemmatized_NA, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score for 4 topics: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_5, texts=data_lemmatized_NA, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score for 5 topics: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb534c",
   "metadata": {},
   "source": [
    "The scores is not as good as we expected due to multiple reason. \n",
    "- We don't know the optimal number of topics that can give the best result\n",
    "- We don't know the alpha and beta values that give the best result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76de79",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef846a7",
   "metadata": {},
   "source": [
    "From a standard LDA model, there are several key parameters that we have to keep in mind and consider programmatically tuning before we invoke the model:\n",
    "1. k number of topics \n",
    "2. alpha parameter represent the document topic density\n",
    "3. beta parameter represent the topic word density\n",
    "\n",
    "**Documentation of LDA Model using Gensim Library: https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a49a513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    # LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=dictionary,num_topics=k, random_state=100,chunksize=100,passes=10,alpha=a,eta=b)\n",
    "    # Coherence model\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "def hyperparameter_tuning(corpus_sets, topics_range, alpha, beta, model_results, corpus_title):\n",
    "    # Can take a long time to run\n",
    "    if 1 == 1:\n",
    "        pbar = tqdm.tqdm(total=540)\n",
    "        # iterate through validation corpuses\n",
    "        for i in range(len(corpus_sets)):\n",
    "            # iterate through number of topics\n",
    "            for k in topics_range:\n",
    "                # iterate through alpha values\n",
    "                for a in alpha:\n",
    "                    # iterare through beta values\n",
    "                    for b in beta:\n",
    "                        # get the coherence score for the given parameters\n",
    "                        cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, k=k, a=a, b=b)\n",
    "                        # Save the model results\n",
    "                        model_results['Validation_Set'].append(corpus_title[i])\n",
    "                        model_results['Topics'].append(k)\n",
    "                        model_results['Alpha'].append(a)\n",
    "                        model_results['Beta'].append(b)\n",
    "                        model_results['Coherence'].append(cv)\n",
    "\n",
    "                        pbar.update(1)\n",
    "        pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf42ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/540 [01:17<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18728/3351985921.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                     \u001b[1;31m# get the coherence score for the given parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                     \u001b[1;31m# Save the model results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[0mmodel_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Validation_Set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18728/1882207467.py\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[1;34m(corpus, dictionary, k, a, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# LDA model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlda_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Coherence model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcoherence_model_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c_v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"auto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         super(LdaMulticore, self).__init__(\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m             self.add_lifecycle_event(\n\u001b[0;32m    522\u001b[0m                 \u001b[1;34m\"created\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[1;34m(force)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \"\"\"\n\u001b[0;32m    273\u001b[0m             \u001b[0mmerged_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mempty\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    333\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    334\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    858\u001b[0m                     \u001b[1;31m# start an overlapped read of length zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m                         \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReadFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileno\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                         \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwinerror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# Topics\n",
    "min_topic = 2\n",
    "max_topic = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topic, max_topic, step_size)\n",
    "\n",
    "# Alpha\n",
    "alpha = list(np.arange(.01, 1, .3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta\n",
    "beta = list(np.arange(.01, 1, .3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets of 75% and 100%\n",
    "doc_num = len(corpus_new)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus_new, int(doc_num*0.75)), \n",
    "               corpus_new]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "hyperparamter_tuning(corpus_sets, topics_range, alpha, beta, model_results, corpus_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b0802",
   "metadata": {},
   "source": [
    "### Evaluation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_result = pd.to_csv(\"lda_tuning_results.csv\")\n",
    "lda_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7a706",
   "metadata": {},
   "source": [
    "#### Plot for topic coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82d82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65b1dc6e",
   "metadata": {},
   "source": [
    "#### Table for Alpha Beta coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfe5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd3345e",
   "metadata": {},
   "source": [
    "#### Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57306713",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea1f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686773c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a746e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f85b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
